{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f889996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2257025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # normalize pixel values to [0,1]\n",
    "        rotation_range=20, # randomly rotate images by 20 degrees\n",
    "        width_shift_range=0.1, # randomly shift images horizontally by 10%\n",
    "        height_shift_range=0.1, # randomly shift images vertically by 10%\n",
    "        shear_range=0.1, # randomly apply shear transformation\n",
    "        zoom_range=0.1, # randomly zoom into images\n",
    "        horizontal_flip=True, # randomly flip images horizontally\n",
    "        fill_mode='nearest' # fill any gaps in the image with the nearest pixel value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbda0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308e931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1238 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'training/', # directory containing training images\n",
    "        target_size=(128, 128), # resize images to 128x128 pixels\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5ca850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'testing/', # directory containing validation images\n",
    "        target_size=(128, 128),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f41622",
   "metadata": {},
   "source": [
    "# Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8dae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f14ce",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6976ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9cdebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 17s 215ms/step - loss: 1.3183 - accuracy: 0.3667 - val_loss: 1.1124 - val_accuracy: 0.5215\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 17s 218ms/step - loss: 1.0453 - accuracy: 0.5468 - val_loss: 0.9064 - val_accuracy: 0.6442\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 18s 224ms/step - loss: 0.9607 - accuracy: 0.5953 - val_loss: 0.6532 - val_accuracy: 0.7638\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 16s 208ms/step - loss: 0.8532 - accuracy: 0.6349 - val_loss: 0.6348 - val_accuracy: 0.7423\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 17s 222ms/step - loss: 0.7212 - accuracy: 0.6963 - val_loss: 0.6477 - val_accuracy: 0.7669\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 17s 216ms/step - loss: 0.6989 - accuracy: 0.7124 - val_loss: 0.6229 - val_accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 18s 231ms/step - loss: 0.6406 - accuracy: 0.7423 - val_loss: 0.4226 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 19s 241ms/step - loss: 0.5826 - accuracy: 0.7544 - val_loss: 0.3566 - val_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 21s 263ms/step - loss: 0.5353 - accuracy: 0.7884 - val_loss: 0.5607 - val_accuracy: 0.7669\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 19s 245ms/step - loss: 0.5076 - accuracy: 0.7819 - val_loss: 0.4172 - val_accuracy: 0.8221\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b3746",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a56a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 62ms/step - loss: 0.4172 - accuracy: 0.8221\n",
      "Test accuracy: 0.8220859169960022\n",
      "Test loss: 0.4171622693538666\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1823e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c51822",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/deepa/Animals/Testing/elephants/images (42).jpeg'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c00368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "Predicted class:  elephants\n",
      "Confidence score:  0.99955267\n"
     ]
    }
   ],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = x / 255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = model.predict(x)\n",
    "class_idx = np.argmax(preds[0])\n",
    "class_names = train_generator.class_indices\n",
    "for name, idx in class_names.items():\n",
    "    if idx == class_idx:\n",
    "        print(\"Predicted class: \", name)\n",
    "        print(\"Confidence score: \", preds[0][class_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fba84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
